{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd095df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from collections import Counter\n",
    "import colorsys\n",
    "import os\n",
    "data = pd.read_csv(\"dataset_copy.csv\", sep=None, engine='python')\n",
    "INPUT_CSV = \"dataset_copy.csv\"  \n",
    "OUTPUT_CSV = \"dataset_thumbnail_featured.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8c32361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[ YouTube API ]  --->  [ dataset_copy.csv ]\\n                             |\\n                             V\\n                    [ Thumbnail Script ] ---> [ dataset_thumbnail_featured.csv ]\\n                             |\\n                             V\\n                    [ Feature Engineering ] (Merge & Clean & Featuring)\\n                             |\\n                             V\\n                    [ data_featured.csv ]\\n                             |\\n                             V\\n                    [ ML Models (XGBoost) ]\\n\\nThis is the roadmap of project and python files.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "[ YouTube API ]  --->  [ dataset_copy.csv ]\n",
    "                             |\n",
    "                             V\n",
    "                    [ Thumbnail Script ] ---> [ dataset_thumbnail_featured.csv ]\n",
    "                             |\n",
    "                             V\n",
    "                    [ Feature Engineering ] (Merge & Clean & Featuring)\n",
    "                             |\n",
    "                             V\n",
    "                    [ data_featured.csv ]\n",
    "                             |\n",
    "                             V\n",
    "                    [ ML Models ]\n",
    "\n",
    "This is the roadmap of project and python files.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2646b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13317 video processed. Continuing\n",
      " 0 will be processed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from collections import Counter\n",
    "import colorsys\n",
    "import os\n",
    "\n",
    "# Initialize the dataframe for processing\n",
    "if 'data' in locals():\n",
    "    df_process = data.copy()\n",
    "else:\n",
    "    df_process = data.copy()\n",
    "\n",
    "def extract_all_color_features(url):\n",
    "\n",
    "    #Downloads an image from a URL and extracts various color based metrics including RGB, HSV, Hex codes, and perceived brightness.\n",
    "\n",
    "    try:\n",
    "        # Return default values if the URL is empty or invalid\n",
    "        if pd.isna(url) or url == \"\":\n",
    "            return pd.Series([0,0,0,0,0,0,\"#000000\",0])\n",
    "\n",
    "        # Download the image content with a 3 second timeout\n",
    "        resp = requests.get(url, timeout=3)\n",
    "        img = Image.open(BytesIO(resp.content)).convert(\"RGB\")\n",
    "\n",
    "        # Reduce the image to 16 colors to simplify the color space\n",
    "        img = img.quantize(colors=16).convert(\"RGB\")\n",
    "\n",
    "        # Resize image for faster pixel analysis and find the most frequent color\n",
    "        pixels = list(img.resize((25, 25)).getdata())\n",
    "        rgb = Counter(pixels).most_common(1)[0][0]\n",
    "\n",
    "        r, g, b = rgb[0], rgb[1], rgb[2]\n",
    "\n",
    "        # Convert RGB to Hexadecimal format\n",
    "        hex_code = \"#{:02x}{:02x}{:02x}\".format(r, g, b)\n",
    "\n",
    "        # Convert RGB to Hue, Saturation, and Value (HSV) scale\n",
    "        h, s, v = colorsys.rgb_to_hsv(r/255.0, g/255.0, b/255.0)\n",
    "        h, s, v = h * 360, s * 100, v * 100\n",
    "\n",
    "        # Calculate brightness as perceived by the human eye\n",
    "        perceived_bright = (r * 0.299 + g * 0.587 + b * 0.114)\n",
    "\n",
    "        return pd.Series([h, s, v, r, g, b, hex_code, perceived_bright])\n",
    "\n",
    "    except:\n",
    "        # Return zeros if any error occurs during image processing\n",
    "        return pd.Series([0,0,0,0,0,0,\"#000000\",0])\n",
    "\n",
    "# Logic to resume processing if the output file already exists\n",
    "start_index = 0\n",
    "if os.path.exists(OUTPUT_CSV):\n",
    "    df_existing = pd.read_csv(OUTPUT_CSV, sep=\";\")\n",
    "    start_index = len(df_existing)\n",
    "    print(f\"{start_index} video processed. Continuing\")\n",
    "else:\n",
    "    # Create a new CSV file with appropriate headers if it does not exist\n",
    "    cols = ['thumb_hue', 'thumb_saturation', 'thumb_brightness',\n",
    "            'thumb_r', 'thumb_g', 'thumb_b',\n",
    "            'thumb_hex', 'thumb_perceived_brightness']\n",
    "\n",
    "    pd.DataFrame(columns=list(df_process.columns) + cols).to_csv(OUTPUT_CSV, sep=\";\", index=False)\n",
    "\n",
    "print(f\" {len(df_process) - start_index} will be processed\")\n",
    "\n",
    "# Process the data in batches of 50 to ensure data safety\n",
    "batch_size = 50\n",
    "batch_data = []\n",
    "rows_to_process = df_process.iloc[start_index:].copy()\n",
    "\n",
    "for index, row in rows_to_process.iterrows():\n",
    "    # Extract features for each row using the defined function\n",
    "    features = extract_all_color_features(row['thumbnail_url'])\n",
    "\n",
    "    # Map extracted features back to the row dictionary\n",
    "    row_data = row.to_dict()\n",
    "    row_data['thumb_hue'] = features[0]\n",
    "    row_data['thumb_saturation'] = features[1]\n",
    "    row_data['thumb_brightness'] = features[2]\n",
    "    row_data['thumb_r'] = features[3]\n",
    "    row_data['thumb_g'] = features[4]\n",
    "    row_data['thumb_b'] = features[5]\n",
    "    row_data['thumb_hex'] = features[6]\n",
    "    row_data['thumb_perceived_brightness'] = features[7]\n",
    "\n",
    "    batch_data.append(row_data)\n",
    "\n",
    "    # Save the batch to CSV and clear memory when batch limit is reached\n",
    "    if len(batch_data) >= batch_size:\n",
    "        pd.DataFrame(batch_data).to_csv(OUTPUT_CSV, sep=\";\", mode='a', header=False, index=False)\n",
    "        print(f\"Progress: {index+1}/{len(df_process)} | Color: {features[6]} | Sat: {features[1]:.0f}\")\n",
    "        batch_data = []\n",
    "\n",
    "# Save any remaining records after the loop finishes\n",
    "if batch_data:\n",
    "    pd.DataFrame(batch_data).to_csv(OUTPUT_CSV, sep=\";\", mode='a', header=False, index=False)\n",
    "    print(\"Done. All feature saved to the 'dataset_thumbnail_featured.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d714bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
